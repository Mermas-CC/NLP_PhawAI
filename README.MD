# AnÃ¡lisis de Sentimientos en Tweets en EspaÃ±ol usando Modelos de NLP

Este repositorio contiene un notebook de Jupyter (`NLP_PHAWAI.ipynb`) que explora y compara tres enfoques diferentes para la clasificaciÃ³n de emociones en tweets en espaÃ±ol. El objetivo es analizar el rendimiento de un modelo clÃ¡sico de Machine Learning, un modelo de Transformer con fine-tuning y un Large Language Model (LLM) en una tarea de PNL.

## ğŸ“ Tabla de Contenidos
* [DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
* [Modelos Implementados](#-modelos-implementados)
* [Dataset](#-dataset)
* [MetodologÃ­a](#ï¸-metodologÃ­a)
* [Resultados y Conclusiones](#-resultados-y-conclusiones)
* [TecnologÃ­as Utilizadas](#ï¸-tecnologÃ­as-utilizadas)
* [CÃ³mo Ejecutar el Notebook](#-cÃ³mo-ejecutar-el-notebook)
* [Autor](#-autor)

## ğŸ“– DescripciÃ³n del Proyecto

El proyecto aborda la tarea de clasificaciÃ³n de emociones en texto. Se utiliza el dataset **EmoEvent**, que contiene tweets en espaÃ±ol asociados a diferentes eventos y etiquetados con una de las siete emociones: `anger`, `disgust`, `fear`, `joy`, `sadness`, `surprise` y `others`.

Se implementan y evalÃºan los siguientes tres modelos:
1.  **Modelo ClÃ¡sico:** RegresiÃ³n LogÃ­stica con vectorizaciÃ³n TF-IDF como lÃ­nea base.
2.  **Modelo Transformer:** Fine-tuning de **BETO**, una versiÃ³n de BERT pre-entrenada en espaÃ±ol.
3.  **Modelo Generativo (LLM):** **Gemini 2.5 Flash** a travÃ©s de su API, utilizando tÃ©cnicas de *zero-shot prompting* (con y sin ejemplos).

## ğŸ¤– Modelos Implementados

### 1. RegresiÃ³n LogÃ­stica con TF-IDF
Este es el modelo de referencia. Utiliza `scikit-learn` para convertir el texto de los tweets en vectores numÃ©ricos usando la tÃ©cnica TF-IDF (Term Frequency-Inverse Document Frequency) y luego entrena un clasificador de RegresiÃ³n LogÃ­stica.
- **LibrerÃ­as:** `Pandas`, `Scikit-learn`.
- **Resultado:** AlcanzÃ³ una precisiÃ³n (accuracy) aproximada del **29%**.

### 2. Fine-Tuning de BETO
Este enfoque utiliza un modelo Transformer pre-entrenado especÃ­ficamente para espaÃ±ol ("BETO"). Se realiza un proceso de fine-tuning sobre el dataset de EmoEvent para adaptar el modelo a la tarea especÃ­fica de clasificaciÃ³n de emociones.
- **LibrerÃ­as:** `Hugging Face Transformers`, `PyTorch`.
- **Resultado:** MostrÃ³ un rendimiento significativamente superior, con una precisiÃ³n por evento que llegÃ³ hasta el **46%** en la categorÃ­a `LaLiga`.

### 3. Gemini 2.5 Flash (Zero-Shot)
Se utiliza el LLM de Google, Gemini, para clasificar los tweets sin un entrenamiento previo (zero-shot). Se probaron dos estrategias de prompting:
- **Prompt sin ejemplos:** Solo se le indica al modelo la tarea y las posibles etiquetas.
- **Prompt con ejemplos (Few-shot):** Se le proporciona al modelo un ejemplo claro para cada una de las siete emociones antes de pedirle que clasifique el nuevo tweet.
- **LibrerÃ­as:** `google-generativeai`.
- **Resultado:** El prompt con ejemplos obtuvo una precisiÃ³n del **43%** en una muestra de 200 tweets, demostrando la importancia del "prompt engineering". El prompt sin ejemplos tuvo un rendimiento considerablemente menor (18%).

## ğŸ“Š Dataset

- **Nombre:** EmoEvent
- **Idioma:** EspaÃ±ol (es)
- **Contenido:** Tweets relacionados con eventos especÃ­ficos (ej. `LaLiga`, `NotreDame`, `Venezuela`).
- **Etiquetas:** `anger`, `disgust`, `fear`, `joy`, `others`, `sadness`, `surprise`.
- **Fuente:** Los datos se cargan directamente desde el repositorio de GitHub: `fmplaza/EmoEvent`.

## âš™ï¸ MetodologÃ­a

El flujo de trabajo seguido en el notebook es el siguiente:

1.  **Carga de Datos:** Se cargan los conjuntos de entrenamiento, validaciÃ³n y prueba desde archivos TSV.
2.  **Limpieza de Texto:** Se aplica una funciÃ³n de preprocesamiento para:
    - Eliminar URLs, menciones de usuario y hashtags.
    - Quitar caracteres especiales y nÃºmeros.
    - Convertir el texto a minÃºsculas.
    - Eliminar espacios extra.
3.  **CodificaciÃ³n de Etiquetas:** Las etiquetas de texto (emociones) se convierten a formato numÃ©rico.
4.  **Entrenamiento y EvaluaciÃ³n:** Cada uno de los tres modelos se entrena (o se utiliza para inferencia, en el caso de Gemini) y se evalÃºa utilizando mÃ©tricas como el reporte de clasificaciÃ³n y la matriz de confusiÃ³n.
5.  **AnÃ¡lisis de Resultados:** Se comparan las mÃ©tricas de rendimiento y se analizan los errores y aciertos, incluyendo un desglose de la precisiÃ³n por evento para el modelo BETO.

## ğŸ“ˆ Resultados y Conclusiones

- El modelo **BETO con fine-tuning** fue el que obtuvo el mejor rendimiento general, demostrando la eficacia de los modelos Transformer para tareas de PNL en espaÃ±ol cuando se adaptan a un dominio especÃ­fico.
- La **RegresiÃ³n LogÃ­stica** sirviÃ³ como una lÃ­nea base Ãºtil, pero su rendimiento fue limitado debido a que no captura el contexto semÃ¡ntico de la misma manera que los modelos mÃ¡s avanzados.
- **Gemini 2.5 Flash** mostrÃ³ un gran potencial, especialmente al utilizar **prompts con ejemplos**, lo que subraya la importancia de guiar adecuadamente a los LLMs para obtener resultados precisos en tareas de *zero-shot*.

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Lenguaje:** Python 3
- **LibrerÃ­as Principales:**
    - `Pandas` y `NumPy` para manipulaciÃ³n de datos.
    - `Scikit-learn` para el modelo de RegresiÃ³n LogÃ­stica y mÃ©tricas de evaluaciÃ³n.
    - `Matplotlib` y `Seaborn` para visualizaciÃ³n de datos.
    - `Hugging Face Transformers` para el fine-tuning del modelo BETO.
    - `google-generativeai` para interactuar con la API de Gemini.
- **Entorno:** Google Colab con aceleraciÃ³n por GPU.

## ğŸš€ CÃ³mo Ejecutar el Notebook

Para ejecutar este notebook y replicar los resultados, sigue estos pasos:

1.  **Clona el repositorio:**
    ```bash
    git clone [https://github.com/tu-usuario/tu-repositorio.git](https://github.com/tu-usuario/tu-repositorio.git)
    cd tu-repositorio
    ```

2.  **Instala las dependencias:**
    Abre el notebook y ejecuta la celda que contiene el siguiente comando:
    ```bash
    !pip install pandas numpy scikit-learn matplotlib seaborn transformers datasets google-generativeai
    ```
    *Nota: `torch` y otras dependencias de `transformers` pueden ser necesarias.*

3.  **Configura la API Key (para el modelo Gemini):**
    - ObtÃ©n una API Key desde [Google AI Studio](https://aistudio.google.com/app/apikey).
    - En Google Colab, ve al panel de la izquierda, haz clic en el Ã­cono de la llave (Secretos) y crea un nuevo secreto llamado `GOOGLE_API_KEY` con tu clave como valor.
    - La celda `userdata.get('GOOGLE_API_KEY')` cargarÃ¡ la clave de forma segura.

4.  **Ejecuta las celdas:**
    - Se recomienda utilizar un entorno de ejecuciÃ³n con **GPU** en Google Colab para acelerar el fine-tuning del modelo BETO. Puedes cambiarlo en `Entorno de ejecuciÃ³n` > `Cambiar tipo de entorno de ejecuciÃ³n`.
    - Ejecuta todas las celdas del notebook en orden.

## âœ¨ Autor

- **Elmer AndrÃ©s Collanqui Casapia**
- ğŸ’» IngenierÃ­a en Sistemas e InformÃ¡tica
- ğŸš€ Aimara Lab
- ğŸ“ Universidad Nacional de Moquegua
- âœ‰ï¸ **Contacto:** [ecollanqui@aimaralab.com](mailto:ecollanqui@aimaralab.com)
- ğŸŒ [GitHub](https://github.com/Mermas-CC) | [LinkedIn](https://www.linkedin.com/in/elmer-andres-collanqui-casapia-977325315)
